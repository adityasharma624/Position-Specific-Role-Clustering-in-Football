{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcbf2c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "import umap\n",
    "import hdbscan\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7a30698",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../dataset/final.csv\")\n",
    "X_scaled = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0a227615",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [02:51<00:00,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    n_neighbors  n_components  min_cluster_size  clusters  silhouette  \\\n",
      "41           30            10                15        12    0.591466   \n",
      "44           30            15                15        12    0.588342   \n",
      "20           10            15                15        18    0.577301   \n",
      "0             5             5                 5        88    0.570767   \n",
      "32           15            15                15        15    0.566135   \n",
      "47           30            20                15        12    0.565342   \n",
      "23           10            20                15        18    0.564896   \n",
      "10            5            20                10        31    0.561091   \n",
      "29           15            10                15        14    0.561065   \n",
      "38           30             5                15        13    0.560925   \n",
      "\n",
      "         dbi  \n",
      "41  0.559537  \n",
      "44  0.544835  \n",
      "20  0.608275  \n",
      "0   0.546334  \n",
      "32  0.606788  \n",
      "47  0.557546  \n",
      "23  0.651105  \n",
      "10  0.594356  \n",
      "29  0.589755  \n",
      "38  0.566191  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "n_neighbors_list = [5, 10, 15, 30]\n",
    "n_components_list = [5, 10, 15, 20]\n",
    "min_cluster_size_list = [5, 10, 15]\n",
    "\n",
    "total_iterations = (\n",
    "    len(n_neighbors_list)\n",
    "    * len(n_components_list)\n",
    "    * len(min_cluster_size_list)\n",
    ")\n",
    "\n",
    "with tqdm(total=total_iterations) as pbar:\n",
    "    \n",
    "    for n_neighbors in n_neighbors_list:\n",
    "        for n_components in n_components_list:\n",
    "            for min_cluster_size in min_cluster_size_list:\n",
    "                \n",
    "                X_umap = umap.UMAP(\n",
    "                    n_neighbors=n_neighbors,\n",
    "                    n_components=n_components,\n",
    "                    min_dist=0.0,\n",
    "                    random_state=42\n",
    "                ).fit_transform(X_scaled)\n",
    "                \n",
    "                clusterer = hdbscan.HDBSCAN(\n",
    "                    min_cluster_size=min_cluster_size,\n",
    "                    min_samples=min_cluster_size,\n",
    "                    cluster_selection_method='leaf'\n",
    "                )\n",
    "                labels = clusterer.fit_predict(X_umap)\n",
    "                \n",
    "                cluster_count = len(set(labels) - {-1})\n",
    "                \n",
    "                if cluster_count == 0:\n",
    "                    pbar.update(1)\n",
    "                    continue\n",
    "                \n",
    "                mask = labels != -1\n",
    "                \n",
    "                try:\n",
    "                    sil = silhouette_score(X_umap[mask], labels[mask])\n",
    "                    dbi = davies_bouldin_score(X_umap[mask], labels[mask])\n",
    "                except:\n",
    "                    sil = np.nan\n",
    "                    dbi = np.nan\n",
    "                \n",
    "                results.append({\n",
    "                    \"n_neighbors\": n_neighbors,\n",
    "                    \"n_components\": n_components,\n",
    "                    \"min_cluster_size\": min_cluster_size,\n",
    "                    \"clusters\": cluster_count,\n",
    "                    \"silhouette\": sil,\n",
    "                    \"dbi\": dbi\n",
    "                })\n",
    "                \n",
    "                pbar.update(1)\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results = df_results.sort_values(\n",
    "    by=[\"silhouette\", \"clusters\"], ascending=[False, True]\n",
    ")\n",
    "\n",
    "print(df_results.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fac17c",
   "metadata": {},
   "source": [
    "Too many clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1c33d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [07:39<00:00, 17.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    n_neighbors  n_components  min_cluster_size  clusters  silhouette  \\\n",
      "9            75            10                20         2    0.842025   \n",
      "10           75            10                25         2    0.842025   \n",
      "11           75            10                30         2    0.842025   \n",
      "12           75            15                20         2    0.830090   \n",
      "13           75            15                25         2    0.830090   \n",
      "14           75            15                30         2    0.830090   \n",
      "15           75            20                20         2    0.810888   \n",
      "16           75            20                25         2    0.810888   \n",
      "17           75            20                30         2    0.810888   \n",
      "18          100            10                20         2    0.807319   \n",
      "\n",
      "         dbi  \n",
      "9   0.224142  \n",
      "10  0.224142  \n",
      "11  0.224142  \n",
      "12  0.241177  \n",
      "13  0.241177  \n",
      "14  0.241177  \n",
      "15  0.266716  \n",
      "16  0.266716  \n",
      "17  0.266716  \n",
      "18  0.271214  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "n_neighbors_list = [50, 75, 100]\n",
    "n_components_list = [10, 15, 20]\n",
    "min_cluster_size_list = [20, 25, 30]\n",
    "\n",
    "total_iterations = (\n",
    "    len(n_neighbors_list)\n",
    "    * len(n_components_list)\n",
    "    * len(min_cluster_size_list)\n",
    ")\n",
    "\n",
    "with tqdm(total=total_iterations) as pbar:\n",
    "    \n",
    "    for n_neighbors in n_neighbors_list:\n",
    "        for n_components in n_components_list:\n",
    "            for min_cluster_size in min_cluster_size_list:\n",
    "                \n",
    "                X_umap = umap.UMAP(\n",
    "                    n_neighbors=n_neighbors,\n",
    "                    n_components=n_components,\n",
    "                    min_dist=0.0,\n",
    "                    random_state=42\n",
    "                ).fit_transform(X_scaled)\n",
    "                \n",
    "                clusterer = hdbscan.HDBSCAN(\n",
    "                    min_cluster_size=min_cluster_size,\n",
    "                    min_samples=min_cluster_size,\n",
    "                    cluster_selection_method = 'eom'\n",
    "                )\n",
    "                labels = clusterer.fit_predict(X_umap)\n",
    "                \n",
    "                cluster_count = len(set(labels) - {-1})\n",
    "                \n",
    "                if cluster_count == 0:\n",
    "                    pbar.update(1)\n",
    "                    continue\n",
    "                \n",
    "                mask = labels != -1\n",
    "                \n",
    "                try:\n",
    "                    sil = silhouette_score(X_umap[mask], labels[mask])\n",
    "                    dbi = davies_bouldin_score(X_umap[mask], labels[mask])\n",
    "                except:\n",
    "                    sil = np.nan\n",
    "                    dbi = np.nan\n",
    "                \n",
    "                results.append({\n",
    "                    \"n_neighbors\": n_neighbors,\n",
    "                    \"n_components\": n_components,\n",
    "                    \"min_cluster_size\": min_cluster_size,\n",
    "                    \"clusters\": cluster_count,\n",
    "                    \"silhouette\": sil,\n",
    "                    \"dbi\": dbi\n",
    "                })\n",
    "                \n",
    "                pbar.update(1)\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results = df_results.sort_values(\n",
    "    by=[\"silhouette\", \"clusters\"], ascending=[False, True]\n",
    ")\n",
    "\n",
    "print(df_results.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13562490",
   "metadata": {},
   "source": [
    "Only 2 Clusters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
