{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcbf2c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import silhouette_score, davies_bouldin_score\n",
    "import umap\n",
    "import hdbscan\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7a30698",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"../dataset/final.csv\")\n",
    "X_scaled = df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a227615",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48/48 [02:43<00:00,  3.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    n_neighbors  n_components  min_cluster_size  clusters  silhouette  \\\n",
      "38           30             5                15        13    0.635233   \n",
      "44           30            15                15        14    0.622799   \n",
      "40           30            10                10        14    0.613833   \n",
      "47           30            20                15        12    0.609399   \n",
      "35           15            20                15        12    0.603254   \n",
      "5             5            10                15        21    0.602688   \n",
      "8             5            15                15        22    0.591396   \n",
      "37           30             5                10        17    0.586987   \n",
      "26           15             5                15        17    0.585410   \n",
      "23           10            20                15        16    0.581100   \n",
      "\n",
      "         dbi  \n",
      "38  0.513496  \n",
      "44  0.514855  \n",
      "40  0.533049  \n",
      "47  0.505334  \n",
      "35  0.577666  \n",
      "5   0.537447  \n",
      "8   0.548448  \n",
      "37  0.558642  \n",
      "26  0.561865  \n",
      "23  0.572342  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "n_neighbors_list = [5, 10, 15, 30]\n",
    "n_components_list = [5, 10, 15, 20]\n",
    "min_cluster_size_list = [5, 10, 15]\n",
    "\n",
    "total_iterations = (\n",
    "    len(n_neighbors_list)\n",
    "    * len(n_components_list)\n",
    "    * len(min_cluster_size_list)\n",
    ")\n",
    "\n",
    "with tqdm(total=total_iterations) as pbar:\n",
    "    \n",
    "    for n_neighbors in n_neighbors_list:\n",
    "        for n_components in n_components_list:\n",
    "            for min_cluster_size in min_cluster_size_list:\n",
    "                \n",
    "                X_umap = umap.UMAP(\n",
    "                    n_neighbors=n_neighbors,\n",
    "                    n_components=n_components,\n",
    "                    min_dist=0.0,\n",
    "                    random_state=42\n",
    "                ).fit_transform(X_scaled)\n",
    "                \n",
    "                clusterer = hdbscan.HDBSCAN(\n",
    "                    min_cluster_size=min_cluster_size,\n",
    "                    min_samples=min_cluster_size,\n",
    "                    cluster_selection_method='leaf'\n",
    "                )\n",
    "                labels = clusterer.fit_predict(X_umap)\n",
    "                \n",
    "                cluster_count = len(set(labels) - {-1})\n",
    "                \n",
    "                if cluster_count == 0:\n",
    "                    pbar.update(1)\n",
    "                    continue\n",
    "                \n",
    "                mask = labels != -1\n",
    "                \n",
    "                try:\n",
    "                    sil = silhouette_score(X_umap[mask], labels[mask])\n",
    "                    dbi = davies_bouldin_score(X_umap[mask], labels[mask])\n",
    "                except:\n",
    "                    sil = np.nan\n",
    "                    dbi = np.nan\n",
    "                \n",
    "                results.append({\n",
    "                    \"n_neighbors\": n_neighbors,\n",
    "                    \"n_components\": n_components,\n",
    "                    \"min_cluster_size\": min_cluster_size,\n",
    "                    \"clusters\": cluster_count,\n",
    "                    \"silhouette\": sil,\n",
    "                    \"dbi\": dbi\n",
    "                })\n",
    "                \n",
    "                pbar.update(1)\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results = df_results.sort_values(\n",
    "    by=[\"silhouette\", \"clusters\"], ascending=[False, True]\n",
    ")\n",
    "\n",
    "print(df_results.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1fac17c",
   "metadata": {},
   "source": [
    "Too many clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1c33d13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 27/27 [07:08<00:00, 15.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    n_neighbors  n_components  min_cluster_size  clusters  silhouette  \\\n",
      "15           75            20                20         2    0.771150   \n",
      "16           75            20                25         2    0.771150   \n",
      "17           75            20                30         2    0.771150   \n",
      "12           75            15                20         2    0.769782   \n",
      "13           75            15                25         2    0.769782   \n",
      "14           75            15                30         2    0.769782   \n",
      "3            50            15                20         2    0.716305   \n",
      "4            50            15                25         2    0.716305   \n",
      "5            50            15                30         2    0.716305   \n",
      "0            50            10                20         2    0.714623   \n",
      "\n",
      "         dbi  \n",
      "15  0.321279  \n",
      "16  0.321279  \n",
      "17  0.321279  \n",
      "12  0.323350  \n",
      "13  0.323350  \n",
      "14  0.323350  \n",
      "3   0.390801  \n",
      "4   0.390801  \n",
      "5   0.390801  \n",
      "0   0.392681  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "n_neighbors_list = [50, 75, 100]\n",
    "n_components_list = [10, 15, 20]\n",
    "min_cluster_size_list = [20, 25, 30]\n",
    "\n",
    "total_iterations = (\n",
    "    len(n_neighbors_list)\n",
    "    * len(n_components_list)\n",
    "    * len(min_cluster_size_list)\n",
    ")\n",
    "\n",
    "with tqdm(total=total_iterations) as pbar:\n",
    "    \n",
    "    for n_neighbors in n_neighbors_list:\n",
    "        for n_components in n_components_list:\n",
    "            for min_cluster_size in min_cluster_size_list:\n",
    "                \n",
    "                X_umap = umap.UMAP(\n",
    "                    n_neighbors=n_neighbors,\n",
    "                    n_components=n_components,\n",
    "                    min_dist=0.0,\n",
    "                    random_state=42\n",
    "                ).fit_transform(X_scaled)\n",
    "                \n",
    "                clusterer = hdbscan.HDBSCAN(\n",
    "                    min_cluster_size=min_cluster_size,\n",
    "                    min_samples=min_cluster_size,\n",
    "                    cluster_selection_method = 'eom'\n",
    "                )\n",
    "                labels = clusterer.fit_predict(X_umap)\n",
    "                \n",
    "                cluster_count = len(set(labels) - {-1})\n",
    "                \n",
    "                if cluster_count == 0:\n",
    "                    pbar.update(1)\n",
    "                    continue\n",
    "                \n",
    "                mask = labels != -1\n",
    "                \n",
    "                try:\n",
    "                    sil = silhouette_score(X_umap[mask], labels[mask])\n",
    "                    dbi = davies_bouldin_score(X_umap[mask], labels[mask])\n",
    "                except:\n",
    "                    sil = np.nan\n",
    "                    dbi = np.nan\n",
    "                \n",
    "                results.append({\n",
    "                    \"n_neighbors\": n_neighbors,\n",
    "                    \"n_components\": n_components,\n",
    "                    \"min_cluster_size\": min_cluster_size,\n",
    "                    \"clusters\": cluster_count,\n",
    "                    \"silhouette\": sil,\n",
    "                    \"dbi\": dbi\n",
    "                })\n",
    "                \n",
    "                pbar.update(1)\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results = df_results.sort_values(\n",
    "    by=[\"silhouette\", \"clusters\"], ascending=[False, True]\n",
    ")\n",
    "\n",
    "print(df_results.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13562490",
   "metadata": {},
   "source": [
    "Only 2 Clusters"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
